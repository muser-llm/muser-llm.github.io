<!DOCTYPE html>
<html lang="en">
<head>
    <script>
    window.MathJax = {
      tex: {
        inlineMath: [['\\(', '\\)']],   
        displayMath: [['\\[', '\\]']],  
        packages: ['base', 'ams']       
      }
    };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MuSeR: Enhancing Medical Context-Awareness of LLMs</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.7;
            color: #333;
            background: #fff;
        }

        .container {
            max-width: 1100px;
            margin: 0 auto;
            padding: 60px 40px;
        }

        header {
            text-align: center;
            margin-bottom: 60px;
        }

        h1 {
            font-size: 2.8em;
            font-weight: 600;
            color: #111;
            margin-bottom: 25px;
            line-height: 1.3;
        }

        .authors {
            font-size: 1.2em;
            color: #666;
            margin-bottom: 20px;
        }

        .links {
            margin-top: 30px;
            display: flex;
            gap: 15px;
            justify-content: center;
            flex-wrap: wrap;
        }

        .links a {
            display: inline-block;
            padding: 12px 28px;
            background: #2563eb;
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 500;
            transition: background 0.3s;
        }

        .links a:hover {
            background: #1d4ed8;
        }

        section {
            margin-bottom: 70px;
        }

        h2 {
            font-size: 2.2em;
            font-weight: 600;
            color: #111;
            margin-bottom: 30px;
        }

        h3 {
            font-size: 1.5em;
            font-weight: 600;
            color: #333;
            margin-top: 35px;
            margin-bottom: 20px;
        }

        p {
            font-size: 1.05em;
            line-height: 1.8;
            margin-bottom: 20px;
            text-align: justify;
        }

        .abstract-text {
            font-size: 1.1em;
            line-height: 1.9;
        }

        ul, ol {
            margin-left: 25px;
            margin-bottom: 20px;
        }

        li {
            margin-bottom: 12px;
            font-size: 1.05em;
            line-height: 1.7;
        }

        .method-list {
            counter-reset: method-counter;
            list-style: none;
            margin-left: 0;
        }

        .method-list > li {
            counter-increment: method-counter;
            margin-bottom: 30px;
            padding-left: 40px;
            position: relative;
        }

        .method-list > li::before {
            content: counter(method-counter) ".";
            position: absolute;
            left: 0;
            font-size: 1.5em;
            font-weight: 600;
            color: #2563eb;
        }

        .method-list > li strong {
            font-size: 1.2em;
            display: block;
            margin-bottom: 10px;
            color: #111;
        }

        .figure {
            margin: 40px 0;
            text-align: center;
        }

        .figure img {
            max-width: 100%;
            height: auto;
            border: 1px solid #e5e7eb;
            border-radius: 8px;
        }

        .figure-caption {
            margin-top: 12px;
            font-size: 0.95em;
            color: #666;
            font-style: italic;
        }

        .placeholder-img {
            width: 100%;
            height: 400px;
            background: linear-gradient(135deg, #f3f4f6 0%, #e5e7eb 100%);
            border: 1px solid #e5e7eb;
            border-radius: 8px;
            display: flex;
            align-items: center;
            justify-content: center;
            color: #9ca3af;
            font-size: 1.1em;
        }

        .highlight-box {
            background: #f0f9ff;
            border-left: 4px solid #2563eb;
            padding: 25px;
            margin: 30px 0;
            border-radius: 4px;
        }

        .metrics {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 25px;
            margin: 35px 0;
        }

        .metric-item {
            text-align: center;
            padding: 25px;
            background: #f9fafb;
            border-radius: 8px;
            border: 1px solid #e5e7eb;
        }

        .metric-value {
            font-size: 2.5em;
            font-weight: 700;
            color: #2563eb;
            display: block;
            margin-bottom: 8px;
        }

        .metric-label {
            font-size: 1em;
            color: #666;
        }

        .resources-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 25px;
            margin-top: 35px;
        }

        .resource-card {
            background: #fff;
            border: 1px solid #e5e7eb;
            border-radius: 8px;
            padding: 30px;
            transition: all 0.3s;
        }

        .resource-card:hover {
            border-color: #2563eb;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);
        }

        .resource-card h3 {
            margin-top: 0;
            font-size: 1.3em;
            margin-bottom: 12px;
        }

        .resource-card p {
            color: #666;
            font-size: 0.98em;
            margin-bottom: 18px;
            text-align: left;
        }

        .resource-card a {
            display: inline-block;
            padding: 10px 20px;
            background: #2563eb;
            color: white;
            text-decoration: none;
            border-radius: 5px;
            font-size: 0.95em;
            font-weight: 500;
            transition: background 0.3s;
        }

        .resource-card a:hover {
            background: #1d4ed8;
        }

        .resource-card a.coming-soon {
            background: #e5e7eb;
            color: #666;
            cursor: not-allowed;
        }

        .citation-box {
            background: #f9fafb;
            border: 1px solid #e5e7eb;
            border-radius: 8px;
            padding: 25px;
            margin-top: 25px;
        }

        .citation-box pre {
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            line-height: 1.6;
            overflow-x: auto;
            color: #333;
        }

        footer {
            text-align: center;
            padding: 40px 20px;
            border-top: 1px solid #e5e7eb;
            margin-top: 80px;
            color: #666;
        }

        @media (max-width: 768px) {
            .container {
                padding: 40px 20px;
            }

            h1 {
                font-size: 2em;
            }

            h2 {
                font-size: 1.8em;
            }

            .links {
                flex-direction: column;
            }

            .links a {
                width: 100%;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>MuSeR: Enhancing the Medical Context-Awareness Ability of LLMs via Multifaceted Self-Refinement Learning</h1>
            <div class="authors">Anonymous Authors</div>
            <div class="links">
                <a href="#">üìÑ Paper</a>
                <a href="https://anonymous.4open.science/r/MuSeR-EC43">üíª Code <br>
  <span style="font-size: 0.8em; color: white;">(coming soon)</span></a>
                <a href="#resources">üì¶ Resources <br>
  <span style="font-size: 0.8em; color: white;">(coming soon)</span></a>
            </div>
        </header>

        <section id="abstract">
            <h2>Abstract</h2>
            <p class="abstract-text">Large language models (LLMs) have shown great promise in the medical domain, achieving strong performance on several benchmarks. However, they continue to underperform in real-world medical scenarios, which often demand stronger <strong>context-awareness</strong>, i.e., the ability to recognize missing or critical details (e.g., user identity, medical history, risk factors) and provide safe, helpful, and contextually appropriate responses.</p>
            <div class="figure">
                <img src="example.pdf" alt="Problem and Method" class="figure-img">
                <div class="figure-caption">(a) Comparison between medical exam questions and real-world medical scenarios. (b) Overview of the proposed MuSeR framework.</div>
            </div>
            <p class="abstract-text">To address this issue, we propose <strong>Multifaceted Self-Refinement (MuSeR)</strong>, a data-driven approach that enhances LLMs' context-awareness along three key facets (decision-making, communication, and safety) through self-evaluation and refinement. Specifically, we first design an attribute-conditioned query generator that simulates diverse real-world user contexts by varying attributes such as role, geographic region, intent, and degree of information ambiguity. An LLM then responds to these queries, self-evaluates its answers along three key facets, and refines its responses to better align with the requirements of each facet. Finally, the queries and refined responses are used for supervised fine-tuning to reinforce the model's context-awareness ability.</p>
            
            <p class="abstract-text">Evaluation results on the latest HealthBench dataset demonstrate that our method significantly improves LLM performance across multiple aspects, with particularly notable gains in the context-awareness axis. Furthermore, by incorporating knowledge distillation with the proposed method, the performance of a smaller backbone LLM (e.g., Qwen3-32B) surpasses its teacher model (GPT-oss-120B), achieving a new SOTA across all open-source LLMs on HealthBench (<strong>63.8%</strong>) and its hard subset (<strong>43.1%</strong>).</p>
        </section>
        
        <section id="method">
            <h2>Method</h2>
            
            <p>To address the limitations of current medical LLMs in real-world scenarios, we introduce <strong>MuSeR (Multifaceted Self-Refinement)</strong>, a novel approach that enhances LLMs' medical context-awareness by synthesizing simulated real-world medical queries and generating context-aware responses by self-refining the answers of LLMs along diverse facets of context-awareness. Specifically, MuSeR features two core components:</p>
            
            <ol class="method-list">
                <li>
                    <strong>Attribute-Conditioned Query Generation</strong>
                    <p>Firstly, we design a query generator to simulate the complexity of real-world query distribution. Specifically, we assume that the real-world query is controlled by a set of attributes (e.g., user role, intent, geographic location). Built on that, the proposed attribute-conditioned query generator first samples a set of attributes from a prior distribution, and then generates a query conditioned on the sampled attributes using a LLM.
    </p>
                    <p>In our framework, we consider a total of seven key attributes for query generation. These attributes are chosen to capture the diversity and complexity of real-world medical queries:</p>
    <ol>
        <li>üßë‚Äç‚öïÔ∏è User identity (patient, caregiver, or doctor)</li>
        <li>üåç Geographic region (country, urban/rural area)</li>
        <li>ü©∫ The specific disease or injury being inquired about</li>
        <li>üéØ User intent (seeking diagnosis, treatment advice, report interpretation, etc.)</li>
        <li>‚ùì Vagueness of the intent (clear, vague)</li>
        <li>üìã Completeness of the provided details (complete, incomplete)</li>
        <li>‚úçÔ∏è Language style (formal, informal)</li>
    </ol>
                </li>
                
                <li>
                    <strong>Multifaceted Self-Refinement</strong>
                    <p>Secondly, we construct a multifaceted self-refinement module where an LLM responds to the generated queries, evaluates its answers along the three key facets, and refines its responses to better align with the requirements of each facet. We primarily consider three key facets of context-awareness that are crucial for providing safe, helpful, and appropriate responses in the medical domain:</p>
                    <ul>
                        <li><strong>Decision-Making Awareness:</strong> This facet focuses on identifying critical information (e.g., medical history, medication, examination results) essential for accurate medical decision-making, as well as actively seeking missing details from users when necessary. Such awareness is critical for ensuring the accuracy and practical utility of medical advice.</li>
                        <li><strong>Communication Awareness:</strong> This facet involves recognizing the user's identity (e.g., patient, doctor) and response preferences, and tailoring both terminology (e.g., layman vs. professional) and level of detail (e.g., brief vs. comprehensive) accordingly. This facet is essential for providing responses that match the user's knowledge background and expectations.</li>
                        <li><strong>Safety Awareness:</strong> This facet requires the model to recognize potential risk factors (e.g., symptom severity, underlying conditions) and ethical considerations (e.g., the use of unproven drugs) in its responses. Such awareness is vital for ensuring both the safety and ethical integrity of the medical advice provided.</li>
                    </ul>
                    <p>For each generated query, the target LLM first generates an initial response. Subsequently, the LLM self-evaluates the answer along each facet above and generates a supplementary rationale to explain how the answer can be improved to better align with the requirements of the facet. For example, for the decision-making awareness facet, the model may identify missing critical information in the query and generate a rationale such as "We should ask about the patient's current medications to make an accurate diagnosis". Finally, the refined answer is generated by prompting the LLM to directly refine the initial answer based on the query and the generated rationales.</p>
                </li>
            </ol>
            <h3>Training Strategy</h3>
            <p>We propose a two-stage supervised finetuning to improve LLMs' medical context awareness:</p>
                <ul>
                    <li><strong>Query-Guided Knowledge Distillation:</strong> This training phase aims to inject essential medical knowledge and reasoning abilities into the target LLM to support context-aware responses. Specifically, a strong teacher LLM first generates high-quality responses for the synthesized queries, and the target LLM is then fine-tuned to align its outputs with those of the teacher before proceeding to the multifaceted self-refinement stage. We observe that this stage not only enhances the medical knowledge and reasoning capabilities of the student model but also improves the effectiveness of the subsequent self-refinement process.</li>

                    <li><strong>Multifaceted Self-Refinement:</strong> Following knowledge distillation, the distilled LLM is further employed to generate multifaceted, self-refined responses. The synthesized queries along with the refined answers are then used for supervised fine-tuning of the distilled model, thereby improving its medical context-awareness and response quality.</li>
                </ul>
            <div class="figure">
                <img src="knowledge_distill.pdf" alt="Training Strategy" class="figure-img">
                <div class="figure-caption">Figure 3: The proposed two-phase training strategy.</div>
            </div>
            
        </section>

        <section id="results">
            <h2>Experimental Results</h2>

            <h3>Performance on HealthBench</h3>
            <p>We evaluate MuSeR on HealthBench, a new medical benchmark constructed by OpenAI that includes 5,000 realistic health conversations annotated by 262 physicians across 60 countries, evaluating LLMs' performance as medical assistants in real-world scenarios. </p>

            <div class="metrics">
                <div class="metric-item">
                    <span class="metric-value">63.8%</span>
                    <span class="metric-label">HealthBench Full Set</span>
                </div>
                <div class="metric-item">
                    <span class="metric-value">43.1%</span>
                    <span class="metric-label">HealthBench Hard Subset</span>
                </div>
                <div class="metric-item">
                    <span class="metric-value">#1</span>
                    <span class="metric-label">Open-Source LLMs</span>
                </div>
                <div class="metric-item">
                    <span class="metric-value">#2</span>
                    <span class="metric-label">All LLMs</span>
                </div>
            </div>

            <div class="highlight-box">
                <strong>Key Finding:</strong> By incorporating knowledge distillation with MuSeR, a smaller backbone model (Qwen3-32B) achieves performance that surpasses its teacher model, establishing a new state-of-the-art among all open-source medical LLMs. The most significant improvements are observed in context-awareness metrics, validating our approach's effectiveness in enhancing this critical capability.
            </div>

            <div class="figure">
                <div class="placeholder-img">Performance Comparison Chart (Add your figure here)</div>
                <div class="figure-caption">Figure 2: Comparison with baseline models on HealthBench</div>
            </div>

            <h3>Key Improvements</h3>
            <ul>
                <li>Significant gains in context-awareness across diverse medical scenarios</li>
                <li>Enhanced ability to identify missing or critical information in user queries</li>
                <li>Improved safety in responses, particularly for ambiguous or high-risk situations</li>
                <li>Better adaptation of communication style to different user contexts and needs</li>
                <li>Superior performance in both standard and challenging test cases</li>
            </ul>

            <div class="figure">
                <div class="placeholder-img">Qualitative Examples (Add your figure here)</div>
                <div class="figure-caption">Figure 3: Qualitative comparison of responses before and after MuSeR refinement</div>
            </div>
        </section>

        <section id="resources">
            <h2>Resources</h2>
            <p>We are committed to open science and reproducible research. The following resources will be released upon publication:</p>

            <div class="resources-grid">
                <div class="resource-card">
                    <h3>üìÑ Paper</h3>
                    <p>Full paper with detailed methodology, experiments, and comprehensive analysis</p>
                    <a href="#" class="coming-soon">Coming Soon</a>
                </div>

                <div class="resource-card">
                    <h3>üíª Code</h3>
                    <p>Complete implementation including training scripts, evaluation pipelines, and data processing tools</p>
                    <a href="https://anonymous.4open.science/r/MuSeR-EC43">View Repository</a>
                </div>

                <div class="resource-card">
                    <h3>üìä Dataset</h3>
                    <p>Curated dataset with attribute-conditioned queries and multi-faceted refined responses</p>
                    <a href="#" class="coming-soon">Coming Soon</a>
                </div>

                <div class="resource-card">
                    <h3>ü§ñ Model Weights</h3>
                    <p>Pre-trained checkpoints for Qwen3-32B fine-tuned with MuSeR</p>
                    <a href="#" class="coming-soon">Coming Soon</a>
                </div>

                <div class="resource-card">
                    <h3>üìö Documentation</h3>
                    <p>Comprehensive guides for training, evaluation, and deployment of MuSeR models</p>
                    <a href="#" class="coming-soon">Coming Soon</a>
                </div>

                <div class="resource-card">
                    <h3>üéØ Demo</h3>
                    <p>Interactive demonstration showcasing MuSeR's context-awareness capabilities</p>
                    <a href="#" class="coming-soon">Coming Soon</a>
                </div>
            </div>
        </section>

        <section id="citation">
            <h2>Citation</h2>
            <p>If you find this work useful for your research, please cite:</p>
            <div class="citation-box">
                <pre>@article{muser2025,
  title={Enhancing the Medical Context-Awareness Ability of LLMs 
         via Multifaceted Self-Refinement Learning},
  author={Anonymous Authors},
  journal={Under Review},
  year={2025}
}</pre>
            </div>
        </section>

        <footer>
            <p>¬© 2025 Anonymous Authors. All rights reserved.</p>
            <p>Contact information will be provided upon deanonymization.</p>
        </footer>
    </div>
</body>
</html>
